import asyncio
import json
import pandas as pd
from fastapi import FastAPI, WebSocket, HTTPException
from util.chrome_drive import driver
from bs4 import BeautifulSoup
import time
import re
from datetime import datetime, timedelta
from util import By, WebDriverWait, EC
from starlette.websockets import WebSocketState
from fastapi.responses import JSONResponse

app = FastAPI()

# ÎßàÏßÄÎßâ 17:59 Îç∞Ïù¥ÌÑ∞Î•º Ï†ÄÏû•Ìï† Ï†ÑÏó≠ Î≥ÄÏàò
LAST_TREEMAP_DATA = {}

def calculate_date(days_ago):
    # ÌòÑÏû¨ ÎÇ†Ïßú
    today = datetime.today()
    # days_ago ÎßåÌÅº Ïù¥Ï†Ñ ÎÇ†Ïßú Í≥ÑÏÇ∞
    target_date = today - timedelta(days=days_ago)
    # ÎÇ†ÏßúÎ•º Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò (YYYY-MM-DD ÌòïÏãù)
    target_date_str = target_date.strftime('%Y-%m-%d')

    return target_date_str

def fetch_data():
    browser = driver()
    try:
        url = "https://finance.finup.co.kr/Lab/ThemeLog"
        browser.get(url)
        WebDriverWait(browser, 30).until(
            EC.presence_of_element_located((By.CLASS_NAME, "contents01"))
        )
        div_first = BeautifulSoup(browser.page_source, "html.parser").find("div", class_="contents01")
        time.sleep(1)
        theme_box = div_first.find(name="div", class_="box_desc on").find(name="div", id="treemap").find_all(name="div")
        time.sleep(1)
        
        theme_rows = []
        for item in theme_box:
            keyword = item.find("div", class_="nodeKeyword")
            diff = item.find("div", class_="nodeDiff")
            code = item.get("id", "")[1:] if item.has_attr("id") else None
            
            if keyword and diff and code:
                diff_text = diff.text.strip().replace('%', '')
                try:
                    diff_value = float(diff_text)
                except ValueError:
                    diff_value = 0.0
                
                theme_rows.append({
                    "theme_name": keyword.text.strip(),
                    "theme_diff": diff.text.strip(),
                    "theme_code": code,
                    "theme_diff_value": diff_value
                })
        
        df = pd.DataFrame(theme_rows)
        return df
    finally:
        browser.quit()

@app.websocket("/ws/theme")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("‚úÖ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ WebSocket Ïó∞Í≤∞Îê®!")

    try:
        while True:
            current_time = datetime.now()
            if 9 <= current_time.hour < 18:
                df = fetch_data()
                data = {
                    "name": "ÌÖåÎßàÏ£º",
                    "children": [
                        {
                            "name": row["theme_name"],
                            "value": float(row["theme_diff"].replace('%', '').replace('+', '').strip()) if row["theme_diff"].replace('%', '').replace('+', '').replace('.', '', 1).replace('-', '').isdigit() else 0,
                            "code": row["theme_code"]
                        }
                        for _, row in df.iterrows()
                    ]
                }
                await websocket.send_text(json.dumps(data, ensure_ascii=False))
                print("‚úÖ WebSocket Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ Ï†ÑÏÜ° ÏôÑÎ£å")
            else:
                await websocket.send_text(json.dumps(LAST_TREEMAP_DATA, ensure_ascii=False))
                print("‚úÖ 18Ïãú Ïù¥ÌõÑ, ÎßàÏßÄÎßâ Îç∞Ïù¥ÌÑ∞ Î∞òÎ≥µ Ï†ÑÏÜ°")

            await asyncio.sleep(60)
    except Exception as e:
        print(f"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}")
    finally:
        if websocket.client_state != WebSocketState.DISCONNECTED:
            await websocket.close()
            print("üîå WebSocket Ïó∞Í≤∞ Ï¢ÖÎ£åÎê®, 3Ï¥à ÌõÑ Ïû¨Ïó∞Í≤∞ ÏãúÎèÑ...")

        await asyncio.sleep(3)  # 3Ï¥à ÎåÄÍ∏∞ ÌõÑ Îã§Ïãú WebSocket Ïó∞Í≤∞ÏùÑ ÏãúÎèÑ
        asyncio.create_task(websocket_endpoint(websocket))  # Ïû¨ÏãúÎèÑ

@app.get("/theme/news")
def get_news(theme_code: str):
    try:
        # ‚úÖ driver() Ìï®Ïàò Ìò∏Ï∂úÎ°ú WebDriver Ï¥àÍ∏∞Ìôî
        browser = driver()

        # ÌÅ¨Î°§ÎßÅÌï† URL ÏÑ§Ï†ï
        url = f"https://finance.finup.co.kr/Theme/{theme_code}"
        browser.get(url)
        time.sleep(1)

        # HTML ÌååÏã± Î∞è Îâ¥Ïä§ Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
        news_data = []
        newsList = BeautifulSoup(browser.page_source, "html.parser").find("ul", id="ulNewsList").find_all(name="li")

        for news in newsList:
            box_txt = news.find(name="div", class_="box_txt")
            date_text = box_txt.find(name="p", class_="cm_color_lg cm_smtxt").text.strip()
            try:
                date = int(re.search(r'\d+', date_text).group())  # Ïà´ÏûêÎßå Ï∂îÏ∂ú
                date = calculate_date(date)
            except (ValueError, AttributeError):
                date = "Ïïå Ïàò ÏóÜÏùå"

            title = box_txt.find(name="p", class_="mt5 cm_txt").text.strip()
            summary = box_txt.find(name="p", class_="mt5 cm_smtxt cm_color_lg").text.strip()
            onclick_attr = news.get('onclick', '')
            match = re.search(r"popupNewsOpen\('(.*?)'\)", onclick_attr)
            url = match.group(1) if match else None

            news_data.append({
                'theme_code': theme_code,
                'news_date': date,
                'title': title,
                'summary': summary,
                'url': url
            })

        # DataFrame ÏÉùÏÑ± Î∞è JSON Î≥ÄÌôò
        news_df = pd.DataFrame(news_data)
        return JSONResponse(content=news_df.to_dict(orient="records"))

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ïò§Î•ò Î∞úÏÉù: {str(e)}")

    finally:
        browser.quit()  # ‚úÖ WebDriver Ï¢ÖÎ£å